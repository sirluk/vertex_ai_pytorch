{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305564da-877a-49f2-b276-1d41b22c29af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "import google.cloud.bigquery as bq\n",
    "from google.cloud.exceptions import NotFound\n",
    "\n",
    "from typing import Union, Sequence, Tuple, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd0f8a-432c-44b9-9dea-407b04075532",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"\"\n",
    "DATASET_NAME = \"vertex_ai\"\n",
    "TABLE_NAME = \"test_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f471f3fb-0b69-4d8d-a41d-2bc7b2791fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bq_create_dataset(project_id: str, dataset_name: str, location='EU') -> bq.dataset.Dataset:\n",
    "    '''Create big query dataset'''\n",
    "    client = bq.Client(project=project_id)\n",
    "    dataset = bq.Dataset(client.dataset(dataset_name))\n",
    "    dataset.location = location\n",
    "    try:\n",
    "        return client.get_dataset(dataset)\n",
    "    except NotFound as e:\n",
    "        return client.create_dataset(dataset)\n",
    "\n",
    "def bq_create_table(\n",
    "    project_id: str,\n",
    "    dataset_name: str,\n",
    "    table_name: str,\n",
    "    schema: list,\n",
    "    date_partition_field: Optional[str] = None,\n",
    "    delete_existing: bool = False\n",
    ") -> bq.table.Table:\n",
    "    '''Create big query table'''\n",
    "    table_ref = '{}.{}.{}'\n",
    "\n",
    "    client = bq.Client(project=project_id)\n",
    "    table_ref = table_ref.format(project_id, dataset_name, table_name)\n",
    "    table = bq.Table(table_ref, schema=schema)\n",
    "\n",
    "    if date_partition_field is not None:\n",
    "        try:\n",
    "            assert [x for x in schema if x.name==date_partition_field][0].field_type == \"TIMESTAMP\"\n",
    "        except:\n",
    "            raise ValueError(\"date_partition_field needs to be type=TIMESTAMP\")\n",
    "        table.time_partitioning = bq.TimePartitioning(\n",
    "            type_=bq.TimePartitioningType.DAY,\n",
    "            field=date_partition_field,  # name of column to use for partitioning\n",
    "            expiration_ms=None,\n",
    "        )  # 90 days\n",
    "\n",
    "    return client.create_table(table, exists_ok=delete_existing)\n",
    "\n",
    "def bq_insert_rows(\n",
    "    rows_to_insert: Union[pd.DataFrame, Sequence[Tuple], Sequence[Dict]],\n",
    "    project_id: str,\n",
    "    dataset_name: str,\n",
    "    table_name: str,\n",
    "    schema: list,\n",
    "    date_partition_field: Optional[str] = None,\n",
    "    try_create: bool = True\n",
    ") -> None:\n",
    "    '''Insert rows into big query table'''    \n",
    "    table_ref = '{}.{}.{}'\n",
    "\n",
    "    client = bq.Client(project=project_id)\n",
    "    table_ref = table_ref.format(project_id, dataset_name, table_name)\n",
    "\n",
    "    try:\n",
    "        table = client.get_table(table_ref.format(project_id, dataset_name, table_name))\n",
    "    except NotFound as e:\n",
    "        if try_create:\n",
    "            table = bq_create_table(\n",
    "                project_id,\n",
    "                dataset_name,\n",
    "                table_name,\n",
    "                schema,\n",
    "                date_partition_field\n",
    "            )\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    if isinstance(rows_to_insert, pd.DataFrame):\n",
    "        return client.insert_rows_from_dataframe(table, rows_to_insert)\n",
    "    else:\n",
    "        return client.insert_rows(table, rows_to_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1740dc59-b462-4daf-a428-a6f5223ec502",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset('sst2', split=\"test\")\n",
    "df = dataset.data.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b833646b-1d80-41ba-9e09-fdb3427fa94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_create_dataset(PROJECT_ID, DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957be77e-d1c5-4cc4-a5c2-21f6aea20c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = [\n",
    "    bq.SchemaField(\"idx\", \"INTEGER\"),\n",
    "    bq.SchemaField(\"sentence\", \"STRING\"),\n",
    "    bq.SchemaField(\"label\", \"INTEGER\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3e51e2-1122-441a-b677-f52d09a61fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_insert_rows(\n",
    "    df,\n",
    "    PROJECT_ID,\n",
    "    DATASET_NAME,\n",
    "    TABLE_NAME,\n",
    "    schema,\n",
    "    try_create=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ede64-2386-49a8-a70a-e094979290b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
